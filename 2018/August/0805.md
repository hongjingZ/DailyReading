
**2018-08-05**

# Mixture of GANs for Clustering

[1] ã€ŠMixture of GANs for Clusteringã€‹

Yang Yu and Wen-Ji Zhou

Abstract: For data clustering, Gaussian mixture model (GMM) is a typical method that trains several Gaussian models to capture the data. Each Gaussian model then provides the distribution information of a cluster. For clustering of high dimensional and complex data, more flexible models rather than Gaussian models are desired. Recently, the generative adversarial networks (GANs) have shown effectiveness
in capturing complex data distribution. Therefore, GAN mixture model (GANMM) would be a promising alternative of GMM. However, we notice
that the non-flexibility of the Gaussian model is essential in the expectation-maximization procedure for training GMM. GAN can have much higher flexibility, which disables the commonly employed expectation-maximization procedure, as that the maximization cannot change the result of the expectation. In this paper, we propose to use the expectation-maximization procedure for training GANMM. The experiments show that the proposed ANMM can have good performance on complex ata as well as simple data.


Conclusions:

In this paper, we propose a mixture model with GAN as the omponents, i.e., GANMM. Mixture models such as Gaussian ixture models are very popular tools for data analysis. owever, traditional distribution models, such as Gaussian distribution, s lack of flexibility for complex data. The recently eveloped GAN model has shown outstanding performance o model complex distributions. Therefore, GANMM can
serve as an alternative mixture model to GMM for complex situations. We noticed that GANMM is hard to be trained by the classical EM procedure. We thus propose to use the -EM procedure, where the -E-step, implemented by a classifier learned from the clusters, introduces some controllable error so that the optimization of GANMM can continue. Several experiment results show that GANMM can drastically improve the clustering performance on complex data from GMM as well as some state-of-the-art approaches, in both of the raw
feature space and abstracted embedded feature space.

Paper: http://www.ijcai.org/proceedings/2018/0423.pdf







