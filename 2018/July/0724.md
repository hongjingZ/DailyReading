
**2018-07-24**

# Siamese Network

[1] 《Learning a similarity metric discriminatively, with application to face verification》

Sumit Chopra, Raia Hadsell, Yann LeCun

Abstract: We present a method for training a similarity metric from data. The method can be used for recognition or verification applications where the number of categories is very large and not known during training, and where the number of training samples for a single category is very small. The idea is to learn a function that maps input patterns into a target space such that the norm in the target space approximates the “semantic” distance in the input space. The method is applied to a face verification task. The learning process minimizes a discriminative loss function that drives the similarity metric to be small for pairs of faces from the same person, and large for pairs from different persons. The mapping from raw to the target space is a convolutional network whose architecture is designed for robustness to geometric distortions. The system is tested on the Purdue/AR face database which has a very high degree of variability in the pose, lighting, expression, position, and artificial occlusions such as dark glasses and obscuring scarves.

Network Structure:

<p align="center"><img width="60%" src="Siamese_arch.png" /></p>

Conclusion:

We present a general discriminative method for learning complex similarity metrics. The method is best suited for classification or verification scenarios where the number of classes is very large, and/or where examples of all the classes are not available at the time of training. We illustrate the method with a face verification application.

Paper: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1467314

Code:  https://github.com/Shicoder/DeepLearning_Demo/tree/master/siamese_tf_mnist

# GAN

[2] 《Improved Techniques for Training GANs》

Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen

Abstract: We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.

Convergent GAN training:
1. Feature matching addresses the instability of GANs by specifying a new objective for the generator that prevents it from overtraining on the current discriminator.
2. Minibatch discriminationn allows us to generate visually appealing samples very quickly, and in this regard it is superior to feature matching.
3. Historical averaging.
4. One-sided label smoothing.
5. Virtual batch normalization.

Assesment of image quality: 
1. Human annotators from MTurk.
2. Inception score. Apply the Inception model to every generated image to get the conditional label distribution $ x^2 $. Images that contain meaningful objects should have a conditional label distribution p(y|x) with low entropy. Moreover, we expect the model to generate varied images, so the marginal R p(y|x = G(z))dz should have high entropy $ \frac{x+y}{y+z} $







